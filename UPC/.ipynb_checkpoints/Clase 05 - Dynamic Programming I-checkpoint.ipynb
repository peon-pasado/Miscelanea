{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 05\n",
    "\n",
    "Para una mejor visualización entrar al siguiente [link](https://nbviewer.jupyter.org/github/racsosabe/Miscelanea/blob/master/UPC/Clase%2005%20-%20Dynamic%20Programming%20I.ipynb)\n",
    "\n",
    "# Requisitos previos\n",
    "\n",
    "* Recursion y Backtracking\n",
    "\n",
    "## Programación Dinámica (DP)\n",
    "\n",
    "La Programación Dinámica (o en su esencia nativa *Optimización Dinámica*) es un paradigma de resolución de problemas de optimización usando precisamente el principio de optimalidad de Bellman.\n",
    "\n",
    "### Principio de Optimalidad de Bellman\n",
    "\n",
    "Richard Bellman, el creador de esta técnica computacional, definió el **principio de optimalidad** que se debe cumplir para que podamos aplicar DP a un problema:\n",
    "\n",
    "**En un camino de decisiones que nos da la solución óptima, se debe cumplir que cualquier subcamino tambien da una solución parcial óptima**\n",
    "\n",
    "Para determinar si un problema con una determinada estructura de solución cumple con este principio se suele demostrar por contradicción o por inducción, aprovechando la característica de optimalidad parcial.\n",
    "\n",
    "#### Camino simple más corto entre dos nodos\n",
    "\n",
    "Supongamos que tenemos un grafo sin múltiples aristas entre dos nodos $G = (V,E)$ y se nos brindan dos nodos $u$ y $v$; se nos pide determinar el camino simple más corto entre ellos (un camino simple es aquel en el que no se pasa por el mismo nodo más de una vez).\n",
    "\n",
    "En un primer esbozo, podemos definir una función $\\delta(x,y)$ tal que nos dé la distancia del camino simple más corto entre los nodos $x$ y $y$. Notemos que esta función cumple con el principio de optimalidad, debido a que si tuviéramos un nodo $w$ tal que pertenece a algún camino simple de $u$ a $v$ con longitud $\\delta(u,v)$, entonces debe darse necesariamente que:\n",
    "\n",
    "$$ \\delta(u,v) = \\delta(u,w) + \\delta(w,v) $$\n",
    "\n",
    "La prueba es tan simple como intuitiva: Si existiera un camino simple con una distancia más corta entre $u$ y $w$, el $\\delta(u,w)$ tendría dicho valor asociado; para $w$ y $v$ se sigue un argumento similar.\n",
    "\n",
    "**Nota:** ¿El camino simple más largo entre dos nodos cumple con el principio de optimalidad?\n",
    "\n",
    "### Almacenamiento de respuestas\n",
    "\n",
    "La programación dinámica es generalmente usada en problemas que deben simular algún proceso para dar una respuesta máxima respecto a una función o para contar la cantidad de soluciones (este último también incluye el determinar si existe o no una solución válida); por lo tanto, es natural pensar que estos procesos se pueden representar como recursiones finitas en las cuales es sencillo determinar si se cumple el principio de optimalidad (debido a que, por definición, una recursión finita siempre llega a sus casos base).\n",
    "\n",
    "Una de las técnicas principales que caracteriza al DP es el almacenamiento de las respuestas. Esta técnica consiste en usar una cantidad de memoria prudente pero necesaria con el fin de mejorar la complejidad de una recursión **finita**. \n",
    "\n",
    "#### Sucesión de Fibonacci\n",
    "\n",
    "Para notar la mejoría al usar el almacenamiento, analicemos un poco la sucesión de fibonacci: La recurrencia es conocida y bastante simple:\n",
    "\n",
    "$$ F(n) = \\left\\{ \\begin{array}{cc} n &n \\in [0,1] \\\\ F(n-1) + F(n-2) &n > 1 \\end{array} \\right. $$\n",
    "\n",
    "Y si usáramos la siguiente forma de calcular el $n$-ésimo término:\n",
    "\n",
    "```Python\n",
    "def F(n):\n",
    "    if n < 2: return n\n",
    "    return F(n - 1) + F(n - 2)\n",
    "```\n",
    "\n",
    "Entonces tendríamos una complejidad de $O(\\phi^{n})$, donde $\\phi$ es el número de oro $\\left(\\phi = \\frac{1 + \\sqrt{5}}{2}\\right)$.\n",
    "\n",
    "Sin embargo, podríamos mejorar esta complejidad usando un arreglo de tamaño $n$ para guardar ahí todas las respuestas procesadas hasta ahora, para cambiar nuestro enfoque a:\n",
    "\n",
    "```Python\n",
    "def F(n):\n",
    "    if n < 2: return n\n",
    "    if n in answer.keys: return answer(n)\n",
    "    answer.insert({n, F(n - 1) + F(n - 2)})\n",
    "    return answer(n)\n",
    "```\n",
    "\n",
    "De esta manera solamente es necesario procesar la respuesta de cada $n$ una sola vez según lo que se necesite. Por las características de la recurrencia, este método tendría complejidad $O(n)$ por el argumento anterior.\n",
    "\n",
    "### Tipos de DP\n",
    "\n",
    "Existen dos formas de usar la programación dinámica, las cuales varían ligeramente dependiendo lo que se desee y la comodidad de la solución.\n",
    "\n",
    "#### DP Top Down - Recursivo\n",
    "\n",
    "El planteamiento usual del DP recursivo es solamente usar dos pasos:\n",
    "\n",
    "1) Definir una solución usando backtracking recursivo y cuyos parámetros sean fácilmente asociables a una posición dentro de una tabla (se pueden usar fácilmente en una hash table, arbol binario de busqueda o un arreglo).\n",
    "\n",
    "2) Antes de procesar cada respuesta verificar si la estructura de datos a usar ya la tiene procesada. Asimismo, antes de devolver la respuesta, marcar dicho estado como visitado y guardar la respuesta.\n",
    "\n",
    "#### DP Bottom Up - Iterativo\n",
    "\n",
    "El planteamiento usual del DP Iterativo es algo diferente al recursivo:\n",
    "\n",
    "1) Definir correctamente la recursión que se usaría para resolver el problema.\n",
    "\n",
    "2) Analizar el orden topológico de los estados del proceso a solucionar.\n",
    "\n",
    "3) Resolver cada estado en dicho orden topológico.\n",
    "\n",
    "**Nota:** El orden topológico es un ordenamiento de los nodos de un grafo tal que un nodo siempre aparece luego de todas sus dependencias (nodos que tienen una arista hacia este).\n",
    "\n",
    "#### Problema de la mochila\n",
    "\n",
    "Recordemos el problema de la mochila, en el que uno tiene $n$ pares $(w_{i}, v_{i}) \\equiv (peso, valor)$ que definen $n$ elementos y una mochila con capacidad $C$. El problema nos pide determinar la máxi de llevar un subconjunto de dichos elementos de tal forma que la suma de pesos no exceda $C$.\n",
    "\n",
    "Para resolver el problema, tenemos una solución usando backtracking, cuyos parámetros son la posición y la capacidad restante:\n",
    "\n",
    "```Python\n",
    "def Knapsack(pos,left):\n",
    "    if pos == n: return 0\n",
    "    ans = Knapsack(pos + 1, left)\n",
    "    if left >= w[pos]:\n",
    "        ans = max(ans, v[pos] + Knapsack(pos + 1, left - w[pos]))\n",
    "    return ans\n",
    "```\n",
    "\n",
    "Realizando un análisis rápido, notamos que hay $2$ opciones en cada posición y por lo tanto nuestra complejidad será de $O(2^{n})$.\n",
    "\n",
    "Sin embargo, esta solución se puede mejorar significativamente usando 2 arreglos extra: `vis` y `memo`, los cuales almacenarán un booleano que diga si el estado ha sido visitado o no y la respuesta de dicho estado, respectivamente.\n",
    "\n",
    "Entonces, podríamos transformar el backtracking a un DP recursivo de la siguiente manera:\n",
    "\n",
    "```Python\n",
    "def Knapsack(pos,left):\n",
    "    if pos == n: return 0\n",
    "    if vis[pos][left]: return memo[pos][left]\n",
    "    ans = Knapsack(pos + 1,left)\n",
    "    if left >= w[pos]:\n",
    "        ans = max(ans, v[pos] + Knapsack(pos + 1, left - w[pos]))\n",
    "    vis[pos][left] = True\n",
    "    memo[pos][left] = ans\n",
    "    return ans\n",
    "```\n",
    "\n",
    "Notemos que existen $nC$ estados diferentes para esta solución y que cada estado se puede procesar en $O(1)$ (sin considerar las llamadas recursivas), por lo que nuestra complejidad total será de $O(nC)$; la cual, en general, es más eficiente que $O(2^{n})$.\n",
    "\n",
    "Ya hemos resuelto el problema llegando a un DP recursivo, la solución usando DP iterativo se deja como ejercicio para la clase.\n",
    "\n",
    "#### Comparación entre DP Iterativo y DP Recursivo\n",
    "\n",
    "Las diferencias más relevantes entre ambos estilos de DP podrían ser resumidas en la siguiente tabla:\n",
    "\n",
    "|              **DP Recursivo**              |                  **DP Iterativo**                  |\n",
    "|:------------------------------------------:|:--------------------------------------------------:|\n",
    "|        No pasa por todos los estados       |             Pasa por todos los estados             |\n",
    "|   Necesita de todos los estados posibles   | Puede necesitar solo algunos estados en su proceso |\n",
    "|  Necesita inicializar la tabla con dummys  |     Necesita inicializar solo los estados base     |\n",
    "| Puede generar RTE por la pila del programa |        No usa mucho de la pila del programa        |\n",
    "|     Puede generar TLE en casos extremos    | Permite calcular la complejidad de manera sencilla |\n",
    "\n",
    "### Problemas Clásicos usando DP - Parte 1\n",
    "\n",
    "#### Rod Cutting\n",
    "\n",
    "El enunciado del problema de Rod Cutting se resume a lo siguiente:\n",
    "\n",
    "Determinar la máxima ganancia que se puede obtener de cortar una barra de madera de longitud $L$ en piezas, tales que para cada longitud se tenga asociado un precio estático $p(l)$.\n",
    "\n",
    "Podemos ver que este problema es equivalente a elegir en qué punto cortar de la barra, por lo que tendríamos la opción de cortar o no para cada uno de estos, siendo la cantidad $L-1$. Debido a lo anterior, presumiblemente obtendríamos una complejidad exponencial $O(2^{L})$ si nos animáramos a usar un algoritmo de Búsqueda Completa.\n",
    "\n",
    "Para resolver el problema de una manera más eficiente, debemos notar lo siguiente:\n",
    "\n",
    "Si definimos $DP(L)$ como la máxima ganancia posible para una barra de longitud $L$, entonces tenemos la opción de realizar cortes de diversos tamaños y luego continuar con el resto de la barra.\n",
    "\n",
    "Esto es:\n",
    "\n",
    "$$ DP(L) = p(l) + f(L - l) \\text{ para algun }l $$\n",
    "\n",
    "Donde $f(L-l)$ es aquella distribución que conviene más luego de realizar el corte de tamaño $l$. \n",
    "\n",
    "Lo que es necesario notar es que, una vez realizado el corte, el nuevo subproblema con $L - l$ es **independiente** del corte $l$, por lo que concluimos que:\n",
    "\n",
    "$$ f = DP $$\n",
    "\n",
    "Y dado que nos basta solo la recursión, porque la filosofía del DP es probar todos los estados posibles, llegamos a que:\n",
    "\n",
    "$$ DP(L) = \\max\\limits_{1 \\leq l \\leq L}{\\left\\{p(l) + DP(L-l)\\right\\}} $$\n",
    "\n",
    "Usando esta recursión es sencillo llegar a una solución:\n",
    "\n",
    "```Python\n",
    "def DP(L):\n",
    "    if L == 0: return 0\n",
    "    if vis[L]: return memo[L]\n",
    "    ans = 0\n",
    "    for l = 1 to L:\n",
    "        ans = max(ans, p[l] + DP(L - l))\n",
    "    vis[L] = True\n",
    "    memo[L] = ans\n",
    "    return ans\n",
    "```\n",
    "\n",
    "Es sencillo notar que existen $L$ diferentes estados para el DP y que cada estado se procesa en $O(L)$, así que tendremos una complejidad de $O(L^{2})$.\n",
    "\n",
    "#### 1D Range Sum\n",
    "\n",
    "El problema de 1D Range Sum nos da un arreglo $A$ y nos pide hallar la máxima suma de algún subarreglo de $A$. Analicemos las soluciones que se nos puedan ocurrir:\n",
    "\n",
    "##### Fuerza Bruta\n",
    "\n",
    "Es sencillo resolver el problema usando fuerza bruta e iterando sobre todos los posibles subarreglos:\n",
    "\n",
    "```Python\n",
    "ans = -inf\n",
    "for l = 0 to n - 1:\n",
    "    for r = l to n - 1:\n",
    "        act = 0\n",
    "        for k = l to r:\n",
    "            act += A[k]\n",
    "        ans = max(ans, act)\n",
    "```\n",
    "\n",
    "Además de simple de programar, su complejidad se concluye de manera rápida: un sólido $O(n^{3})$.\n",
    "\n",
    "##### Optimizar la Fuerza Bruta\n",
    "\n",
    "Para poder evitar usar el 3 anidamiento de los 3 bucles, podemos mantener un arreglo extra llamado $S[n]$ en donde $S[i]$ mantendrá la suma de todos los elementos de $A$ en las posiciones $[1, i]$:\n",
    "\n",
    "$$ S[i] = \\sum\\limits_{i = 1}^{i} A[i] $$\n",
    "\n",
    "De esta forma tendremos que:\n",
    "\n",
    "$$ sum(L, R) = \\left\\{ \\begin{array}{cc} S[R] &L = 0 \\\\ S[R] - S[L - 1] &L > 1 \\end{array} \\right. $$\n",
    "\n",
    "Y debido a que podemos preprocesar $S$, el 3er bucle anidado se convierte en una consulta $O(1)$.\n",
    "\n",
    "```Python\n",
    "ans = -inf\n",
    "for l = 0 to n - 1:\n",
    "    for r = l to n - 1:\n",
    "        act = S[r] if l == 0 else S[r] - S[l - 1]\n",
    "        ans = max(ans, act)\n",
    "```\n",
    "\n",
    "Llegamos a una complejidad de $O(n^{2})$.\n",
    "\n",
    "##### Usar DP\n",
    "\n",
    "Para resolver el problema de manera aún más eficiente, podemos usar DP. Definamos la función $DP(i)$ como la máxima suma de todos los subarreglos que terminan en la posición $i$, entonces no es muy difícil notar que:\n",
    "\n",
    "$$ DP(i) = A[i] + f(i-1) $$\n",
    "\n",
    "Donde $f(i-1)$ nos da la mejor suma de algún subarreglo que esté conectado a $i$ de manera contigua. Sin embargo, la definición de $f(i - 1)$ es la misma que la de $DP(i)$ pero con una pequeña variación: Si $f(i-1)$ es negativo, entonces me conviene solo tomar $A[i]$.\n",
    "\n",
    "Finalmente podemos llegar a la conclusión de que:\n",
    "\n",
    "$$ DP(0) = A[0] $$\n",
    "$$ DP(i) = A[i] + \\max{\\left\\{0,DP(i-1)\\right\\}} $$\n",
    "\n",
    "Y simplemente tomamos el $DP(i)$ máximo.\n",
    "\n",
    "```Python\n",
    "ans = A[0]\n",
    "memo[0] = A[0]\n",
    "for i = 1 to n - 1:\n",
    "    memo[i] = A[i] + max(memo[i - 1], 0)\n",
    "    ans = max(ans, memo[i])\n",
    "```\n",
    "\n",
    "Debido a que solo tenemos $n$ posibles estados y cada estado se procesa en $O(1)$ llegamos a la conclusión de que nuestra solución es $O(n)$. Se puede reducir la memoria extra de $O(n)$ a $O(1)$ notando que nos basta $DP(i - 1)$ para hallar $DP(i)$ y usar solamente dos variables: 1 para la respuesta y otra para $DP(i - 1)$\n",
    "\n",
    "```Python\n",
    "ans = A[0]\n",
    "prvmemo = A[0]\n",
    "for i = 1 to n - 1:\n",
    "    prvmemo = A[i] + max(prvmemo, 0)\n",
    "    ans = max(ans, prvmemo)\n",
    "```\n",
    "\n",
    "##### Alternativa: Análisis de prefijos\n",
    "\n",
    "Podemos considerar el máximo subarreglo que termine en la posición $r$ como $S[r] - \\min_{0 \\leq l < r}{\\{S[l]\\}}$, así que podemos mantener en una variable extra el mínimo valor de los prefijos anteriores y restarlo del prefijo que tenemos actualmente:\n",
    "\n",
    "```Python\n",
    "ans = 0\n",
    "minprefix = 0\n",
    "for i = 0 to n - 1:\n",
    "    cur_ans = S[i] - minprefix\n",
    "    ans = max(ans, cur_ans)\n",
    "    minprefix = min(minprefix, S[i])\n",
    "```\n",
    "\n",
    "La complejidad es de $O(n)$ y la memoria extra es $O(1)$.\n",
    "\n",
    "#### Problemas para resolver en clase\n",
    "\n",
    "- [Educational DP Contest](https://atcoder.jp/contests/dp/tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 06\n",
    "\n",
    "Para una mejor visualización entrar al siguiente [link](https://nbviewer.jupyter.org/github/racsosabe/Miscelanea/blob/master/UPC/Clase%2006%20-%20Dynamic%20Programming%20II.ipynb)\n",
    "\n",
    "# Requisitos previos\n",
    "\n",
    "* Programación Dinámica I\n",
    "* Principio de Optimalidad de Bellman\n",
    "\n",
    "### Problemas Clásicos usando DP - Parte 2\n",
    "\n",
    "#### 2D Range Sum\n",
    "\n",
    "Para el caso de 2 dimensiones, el problema de 2D Range Sum se transforma de buscar el subarreglo con máxima suma de elementos a buscar la submatriz con máxima suma de elementos. \n",
    "\n",
    "De manera análoga al caso de 1 dimensión, si usamos fuerza bruta directa obtendríamos una complejidad de $O(n^{6})$, donde $n$ es el máximo de las dos dimensiones de la matriz original $A$.\n",
    "\n",
    "Podemos usar principio inclusión-exclusión para obtener las sumas de todos los elementos desde el $(1, 1)$ al $(i, j)$ como extremos de una submatriz:\n",
    "\n",
    "$$ ac[i][j] = A[i][j] + ac[i - 1][j] + ac[i][j - 1] - ac[i - 1][j - 1] $$\n",
    "\n",
    "El primer término es debido a que debemos agregar obligatoriamente el valor $A[i][j]$ a la suma, los dos siguientes son la posición de arriba y la de la izquierda a la celda $(i, j)$, las cuales asumiremos como procesadas antes que $(i, j)$ (Así que iremos por $i$ ascendente y $j$ ascendente) y el último término lo restamos debido a que la submatriz desde $(1, 1)$ a $(i - 1, j - 1)$ la estaríamos agregando dos veces.\n",
    "\n",
    "Podemos obtener $ac[i][j]$ en $O(n^{2})$, ahora debemos analizar cómo hallar la suma de una submatriz:\n",
    "\n",
    "$$ suma(x_{1}, y_{1}, x_{2}, y_{2}) = ac[x_{2}][y_{2}] + ac[x_{1} - 1][y_{1} - 1] - ac[x_{1} - 1][y_{2}] - ac[x_{2}][y_{1} - 1] $$\n",
    "\n",
    "El primer término es el total desde $(1, 1)$ a $(x_{2}, y_{2})$, al cual debemos restarle la celda arriba de $(x_{1}, y_{2})$ y la celda de la izquierda de $(x_{2}, y_{1})$; sin embargo, estaríamos restando la submatriz de $(1, 1)$ a $(x_{1} - 1, y_{1} - 1)$ dos veces, por eso equilibramos con el segundo término.\n",
    "\n",
    "Como podemos obtener la suma de una submatriz en $O(1)$, podemos usar fuerza bruta para fijar cada submatriz posible y maximizar la respuesta, esto nos tomará $O(n^{4})$.\n",
    "\n",
    "##### Mejorando la complejidad\n",
    "\n",
    "Si bien la solución anterior suele ser suficiente en la mayoría de problemas, si necesitamos una mejora en la complejidad podemos notar lo siguiente:\n",
    "\n",
    "*Si fijamos los dos extremos de una de las dimensiones, la suma de cada posición es fija y estaríamos resolviendo un problema en 1 dimensión*\n",
    "\n",
    "Ahora podemos fijar los dos extremos de las filas $x_{1}$ y $x_{2}$ para que cada columna $j$ tenga un valor \n",
    "\n",
    "$$ b_{j} = \\sum\\limits_{i = x_{1}}^{x_{2}}A[i][j] $$\n",
    "\n",
    "Finalmente, aplicamos el algoritmo $O(n)$ para 1D Range Sum sobre $b$ y maximizamos con la respuesta.\n",
    "\n",
    "La complejidad final será de $O(n^{3})$ si usamos prefix sums por columnas para hallar $b_{j}$ en $O(1)$.\n",
    "\n",
    "#### Longest Increasing Subsequence\n",
    "\n",
    "El enunciado de este problema es el siguiente: Se tienen $n$ elementos que están sujetos a un orden parcial, se desea hallar la longitud de la subsecuencia ordenada más larga de todas.\n",
    "\n",
    "La idea usando fuerza bruta tiene complejidad exponencial, así que no nos conviene usarla en absoluto. En cambio, consideraremos el siguiente enfoque, parecido al que usamos en 1D Range Sum:\n",
    "\n",
    "Definimos la función $DP(i)$ como la longitud de la máxima subsecuencia que termina exactamente en la posición $i$, entonces esta función tiene la siguiente característica:\n",
    "\n",
    "$$ DP(i) = \\max\\limits_{j < i, a_{j} \\prec a_{i}}{\\{f(j) + 1\\}} $$\n",
    "\n",
    "Donde $f(j)$ es una función tal que halla el mejor ajuste para que el resultado de $i$ sea óptimo.\n",
    "\n",
    "Sin embargo, estas soluciones se pueden considerar como incrementales (es decir, se van agregando posibles elementos a la solución) y, por ello, el elemento nuevo no puede afectar a lo que se procesó en el pasado, así que son independientes. Recordemos que si los objetivos de optimización son independientes, entonces cada parte por sí sola es óptima: el problema cumple con el principio de optimalidad de Bellman.\n",
    "\n",
    "Dado que el problema cumple con nuestro principio de optimalidad, podemos notar que $f = DP$ pues el $j$ *ignora* el futuro resultado de $i$ para procesarse a sí mismo. Finalmente llegamos a que:\n",
    "\n",
    "$$ DP(i) = \\max\\limits_{j < i, a_{j} \\prec a_{i}}{\\{DP(j) + 1\\}} $$\n",
    "\n",
    "Lo cual puede ser implementado de diferentes maneras, siendo la menos eficiente un $O(n^{2})$. \n",
    "\n",
    "La versión recursiva se implementaría así:\n",
    "\n",
    "```Python\n",
    "def DP(i):\n",
    "    if i == 0: return 1\n",
    "    if vis[i]: return memo[i]\n",
    "    ans = 1\n",
    "    for j = 0 to i - 1:\n",
    "        if a[j] < a[i]: ans = max(ans, 1 + DP(j))\n",
    "    vis[i] = True\n",
    "    memo[i] = ans\n",
    "    return memo[i]\n",
    "```\n",
    "\n",
    "Para la versión iterativa debemos notar que para calcular $(i, j)$ necesitamos de $(i - 1, j)$, $(i, j - 1)$ y en el peor de los casos también de $(i - 1, j - 1)$. Respecto a $i$, dos posiciones nos señalan que debemos calcular por $i$ creciente, pues necesitamos la fila $i - 1$ antes de la $i$. Respecto a $j$, cuando estamos en la fila $i$, necesitamos de $(i, j - 1)$, lo que significa que debemos procesar por $j$ creciente también.\n",
    "\n",
    "```Python\n",
    "def DP():\n",
    "    ans = 1\n",
    "    memo[0] = 1\n",
    "    for i = 1 to n - 1:\n",
    "        memo[i] = 1\n",
    "        for j = 0 to i - 1:\n",
    "            if a[j] < a[i]: memo[i] = max(memo[i], 1 + memo[j])\n",
    "        ans = max(ans, memo[i])\n",
    "    return ans\n",
    "```\n",
    "\n",
    "##### Versión $O(n\\log{n})$\n",
    "\n",
    "La versión $O(n\\log{n})$ a continuación no usa estructuras de datos, solamente se basa en búsqueda binaria para hallar la mejor posición en la que puede ir un valor $x$.\n",
    "\n",
    "Definimos $L(i)$ como el menor valor posible $x$ tal que existe una secuencia creciente de longitud $i$ entre los valores ya procesados y su último término es $x$. Inicializaremos $L$ con $\\infty$ para $i > 0$ y $L_{0} = -\\infty$.\n",
    "\n",
    "A medida que avanzamos en el arreglo $a$, colocaremos la posición $a_{i}$ en el mayor $j$ posible tal que $L_{j - 1} < a_{i}$, este valor lo podemos hallar usando búsqueda binaria, pues $L$ es no decreciente (¿Por qué?).\n",
    "\n",
    "Ya que por cada posición usaremos una búsqueda binaria para hallar $j$, tendremos una complejidad final de $O(n\\log{n})$.\n",
    "\n",
    "#### Longest Common Subsequence\n",
    "\n",
    "El enunciado de este problema es el siguiente: Se tienen dos cadenas $a$ y $b$ de longitudes $n$ y $m$, respectivamente; se desea dar la longitud de la subsecuencia de caracteres más larga que pertenezca a ambas cadenas.\n",
    "\n",
    "Para resolver este problema ya ni es necesario pensar en la solución con fuerza bruta, dado que la más óptima de ellas igual tendrá complejidad exponencial. Esto nos obliga a analizar un poco más las características de la solución.\n",
    "\n",
    "**Observación 1:** Al ser la respuesta una subsecuencia con la característica de que será la más larga de todas, entonces no hay diferencia entre procesar la respuesta de izquierda a derecha o de derecha a izquierda.\n",
    "\n",
    "Supongamos que hemos analizado y procesado la respuesta para los caracteres del $i$ hasta el $n$ en $a$ y del $j$ hasta el $m$ en $b$, entonces notemos que la respuesta de los caracteres restantes no se ve afectada por los que ya están procesados (uno puede verlo como si hubiese eliminado dichos caracteres), por lo que la solución para los restantes debe ser óptima también. Lo anterior nos ayuda a probar que el problema cumple con el principio de optimalidad de Bellman.\n",
    "\n",
    "Dado el análisis previo, podemos plantear la recursión para resolver el problema:\n",
    "\n",
    "$$ DP(i,j) = \\left\\{ \\begin{array}{cc} \\max{\\{DP(i-1,j), DP(i,j-1)\\}} &a_{i} \\neq b_{j} \\\\ 1 + DP(i-1,j-1) &a_{i} = b_{j} \\end{array}\\right. $$\n",
    "\n",
    "La expresión en palabras de la función recursiva se puede lograr fácilmente debido a que nuestro predicado está bien definido:\n",
    "\n",
    "La solución para los primeros $i + 1$ y los primeros $j + 1$ caracteres de $a$ y $b$ respectivamente tiene dos posibles casos: si los caracteres en dichas posiciones son diferentes, solo nos queda probar quitando alguno de los dos y tomar el valor máximo de las dos posibilidades; si los caracteres en dichas posiciones son iguales, nos conviene tomar a los dos y seguir con los demás (el hecho de que ya no se pruebe con quitar alguno de los dos caracteres es debido a que cualquiera de esos intentos no mejorará la respuesta final, por lo que es una transición innecesaria).\n",
    "\n",
    "Finalmente, usando almacenamiento, podemos resolver el problema en $O(n^{2})$.\n",
    "\n",
    "La versión recursiva se implementaría así:\n",
    "\n",
    "```Python\n",
    "def DP(i, j):\n",
    "    if i == -1 or j == -1: return 0\n",
    "    if vis[i][j]: return memo[i][j]\n",
    "    ans = max(DP(i - 1, j), DP(i, j - 1))\n",
    "    if a[i] == b[j]: ans = max(ans, 1 + DP(i - 1, j - 1))\n",
    "    vis[i][j] = True\n",
    "    memo[i][j] = ans\n",
    "    return memo[i][j]\n",
    "```\n",
    "\n",
    "Para la versión iterativa debemos notar que para calcular $(i, j)$ necesitamos de $(i - 1, j)$, $(i, j - 1)$ y en el peor de los casos también de $(i - 1, j - 1)$. Respecto a $i$, dos posiciones nos señalan que debemos calcular por $i$ creciente, pues necesitamos la fila $i - 1$ antes de la $i$. Respecto a $j$, cuando estamos en la fila $i$, necesitamos de $(i, j - 1)$, lo que significa que debemos procesar por $j$ creciente también.\n",
    "\n",
    "```Python\n",
    "def DP():\n",
    "    for i = 0 to n - 1:\n",
    "        for j = 0 to m - 1:\n",
    "            memo[i][j] = -inf\n",
    "            if i > 0: memo[i][j] = max(memo[i][j], memo[i - 1][j])\n",
    "            if j > 0: memo[i][j] = max(memo[i][j], memo[i][j - 1])\n",
    "            if a[i] == b[j]: memo[i][j] = max(memo[i][j], 1 + memo[i - 1][j - 1])\n",
    "    return memo[n - 1][m - 1]\n",
    "```\n",
    "\n",
    "#### Edit distance\n",
    "\n",
    "El enunciado de este problema es el siguiente: Se tienen dos cadenas $a$ y $b$ de longitudes $n$ y $m$, respectivamente; uno puede aplicar las siguientes operaciones sobre la cadena $a$:\n",
    "\n",
    " - Eliminar un caracter bajo un costo $c_{e}$.\n",
    " - Insertar un caracter en cualquier posición bajo un costo $c_{i}$\n",
    " - Reemplazar un caracter bajo un costo $c_{r}$.\n",
    " \n",
    "Se nos pide el costo mínimo con el que uno puede transformar a $a$ en $b$.\n",
    "\n",
    "Al igual que en el problema de LCS, uno debe modelar la recursión considerando igualar los primeros $i + 1$ caracteres de $a$ con los $j + 1$ primeros caracteres de $b$ y analizar las transiciones correspondientes. Sea $DP(i, j)$ la respuesta para lo descrito anteriormente:\n",
    "\n",
    " - $(i - 1, j)$: Se borró el caracter en la posición $i$, así que hay un costo extra de $c_{e}$.\n",
    " - $(i, j - 1)$: Se insertó el caracter $b_{j}$ a la derecha de la posición $i$, así que hay un costo extra de $c_{i}$.\n",
    " - $(i - 1, j - 1)$: Se reemplazó el caracter $a_{i}$ con el caracter $b_{j}$, así que hay un costo extra de $c_{r}$.\n",
    "\n",
    "Finalmente, podemos simplemente aplicar programación dinámica para hallar el mejor resultado de volver iguales los estados de las transiciones:\n",
    "\n",
    "$$ DP(i, j) = \\min{\\{DP(i - 1, j) + c_{e}, DP(i, j - 1) + c_{i}, DP(i - 1, j - 1) + c_{r}\\}} $$\n",
    "\n",
    "La versión recursiva se implementaría así:\n",
    "\n",
    "```Python\n",
    "def DP(i, j):\n",
    "    if i == -1: return c_i * (j + 1)\n",
    "    if j == -1: return c_e * (i + 1)\n",
    "    if vis[i][j]: return memo[i][j]\n",
    "    ans = min([DP(i - 1, j) + c_e, DP(i, j - 1) + c_i, DP(i - 1, j - 1) + c_r])\n",
    "    vis[i][j] = True\n",
    "    memo[i][j] = ans\n",
    "    return memo[i][j]\n",
    "```\n",
    "\n",
    "Para la versión iterativa ya sabemos que debemos iterar de manera similar al problema del LCS por tener las mismas características en los estados; sin embargo, indexaremos desde $1$ para poder considerar los casos $i = -1$ como $i = 0$:\n",
    "\n",
    "```Python\n",
    "def DP():\n",
    "    for i = 0 to n: memo[i][0] = i * c_e\n",
    "    for j = 0 to n: memo[0][j] = j * c_i\n",
    "    for i = 1 to n:\n",
    "        for j = 1 to m:\n",
    "            memo[i][j] = min([memo[i - 1][j] + c_e, memo[i][j - 1] + c_i, memo[i - 1][j - 1] + c_r])\n",
    "    return memo[n][m]\n",
    "```\n",
    "\n",
    "#### Matrix Chain Multiplication\n",
    "\n",
    "El enunciado de este problema es el siguiente: Se tienen $n$ matrices $A_{i}$ definidas por sus dimensiones en un arreglo $p_{i}$, tal que $A_{i} \\in \\mathbb{R}^{p_{i}\\times p_{i+1}}$, las cuales se quieren multiplicar usando la menor cantidad de operaciones posible. Esta forma óptima de multiplicación se debe obtener únicamente colocando paréntesis en donde convenga **sin reordenar** las matrices.\n",
    "\n",
    "Para resolver este problema usando fuerza bruta debemos considerar que tenemos la posibilidad de colocar $\\left\\lfloor\\frac{n+1}{2} \\right\\rfloor$ pares de paréntesis como máximo y que el resultado final debe ser una expresión correctamente balanceada. Esta cantidad de formas nos hace recordar a los números de Catalán, los cuales tienen un crecimiento asintótico de $O\\left(\\frac{4^{n}}{n^{\\frac{3}{2}}\\Pi}\\right)$: para nada eficiente.\n",
    "\n",
    "Sin embargo, podríamos analizar el problema con un estilo Divide and Conquer, considerando que si colocamos paréntesis para separar dos subsecuencias contiguas de la original, el problema se reduce a resolver ambas partes:\n",
    "\n",
    "$$ A_{1}\\cdot A_{2} \\ldots A_{n} = (A_{1}\\ldots A_{k})(A_{k+1}\\ldots A_{n}) $$\n",
    "\n",
    "En este momento, debemos considerar algunas cosas:\n",
    "\n",
    "1) El separar la secuencia en dichas partes nos dice que eventualmente multiplicaremos dos matrices de $p_{1}\\times p_{k+1}$ con una de $p_{k+1}\\times p_{n+1}$, dándonos un peor costo de $p_{1}p_{k+1}p_{n+1}$ mediante la multiplicación trivial de matrices.\n",
    "\n",
    "2) Luego de separar la secuencia, debemos resolver ambas partes de la *mejor manera* para que encajen con la solución eventual señalada en el punto 1, pero debemos notar que ambas soluciones son independientes entre sí y del valor generado por la división. Lo anterior nos sirve para probar que la resolución de ambas partes debe ser óptima y el problema cumple con el principio de Optimalidad de Bellman\n",
    "\n",
    "Con el análisis anterior, podemos plantear una recursión simple:\n",
    "\n",
    "$$ DP(L,R) = \\max\\limits_{L \\leq k < R}{\\left\\{DP(L,k) + DP(k+1,R) + p_{L}p_{k}p_{R+1}\\right\\}} $$\n",
    "\n",
    "Con $DP(i,i) = 0$, $\\forall i = 1, \\ldots, n$.\n",
    "\n",
    "Y usando nuestra técnica de almacenamiento podemos implementar la solucion, cuya complejidad es de $O(n^{3})$.\n",
    "\n",
    "La versión recursiva se implementaría así:\n",
    "\n",
    "```Python\n",
    "def DP(L, R):\n",
    "    if L == R: return 0\n",
    "    if vis[L][R]: return memo[L][R]\n",
    "    ans = inf\n",
    "    for k = L to R - 1:\n",
    "        ans = min(ans, DP(L, k) + DP(k + 1, R) + p[L] * p[k] * p[R + 1])\n",
    "    vis[L][R] = True\n",
    "    memo[L][R] = ans\n",
    "    return memo[L][R]\n",
    "```\n",
    "\n",
    "Mientras que para la versión iterativa debemos notar que para resolver $[L, R]$ debemos saber las respuestas de matrices de menor longitud $[l, r]$ ($R - L + 1 > r - l + 1$), así que iteraremos por tamaño creciente.\n",
    "\n",
    "```Python\n",
    "def DP():\n",
    "    for i = 0 to n - 1:\n",
    "        memo[i][i] = 0\n",
    "    for l = 2 to n:\n",
    "        for L = 0 to n - l:\n",
    "            R = L + l - 1\n",
    "            memo[L][R] = inf\n",
    "            for k = L to R - 1:\n",
    "                memo[L][R] = min(memo[L][R], memo[L][k] + memo[k + 1][R] + p[L] * p[k] * p[R + 1])\n",
    "    return memo[0][n - 1]\n",
    "```\n",
    "\n",
    "\n",
    "### Reconstrucción de Soluciones\n",
    "\n",
    "Para reconstruir las soluciones procesadas por DP, es necesario notar la naturaleza de las transiciones entre estados. Cada estado tiene un conjunto de transiciones que logran obtener una respuesta óptima (dependiendo del problema, podríamos elegir cualquiera o alguno con una característica especial), por lo que basta con almacenar la transición adecuada mediante una tabla extra (considerando la poca cantidad de opciones de transición por estado). Luego de almacenar las transiciones óptimas por estado, podemos recuperar la solución mediante una forma iterativa o incluso recursiva, que tendrá por complejidad $O(\\text{longitud de la respuesta})$, siempre llamando desde el estado inicial de solución.\n",
    "\n",
    "#### Ejemplo - Knapsack Problem\n",
    "\n",
    "El algoritmo recursivo para resolver el problema de la mochila es el siguiente:\n",
    "\n",
    "```Python\n",
    "def Knapsack(pos,left):\n",
    "    if pos == n: return 0\n",
    "    if vis[pos][left]: return memo[pos][left]\n",
    "    ans = Knapsack(pos + 1, left)\n",
    "    if left >= w[pos]:\n",
    "        ans = max(ans, v[pos] + Knapsack(pos + 1, left - w[pos]))\n",
    "    vis[pos][left] = True\n",
    "    return memo[pos][left] = ans\n",
    "```\n",
    "\n",
    "Y por cada estado tenemos la opción entre usar o no usar el elemento $pos$, así que solamente crearemos un arreglo booleano extra que mantenga $True$ si el elemento $pos$ fue tomado y $False$ si no lo fue.\n",
    "\n",
    "```Python\n",
    "def Knapsack(pos,left):\n",
    "    if pos == n: return 0\n",
    "    if vis[pos][left]: return memo[pos][left]\n",
    "    ans = Knapsack(pos + 1, left)\n",
    "    choice[pos][left] = False # Asumo que no me conviene tomarlo\n",
    "    if left >= w[pos]:\n",
    "        if ans < v[pos] + Knapsack(pos + 1, left - w[pos]): # Me conviene tomarlo\n",
    "            ans = v[pos] + Knapsack(pos + 1, left - w[pos]) \n",
    "            choice[pos][left] = True # Actualizo la decision optima\n",
    "    vis[pos][left] = True\n",
    "    return memo[pos][left] = ans\n",
    "```\n",
    "\n",
    "Entonces podemos reconstruir la solución usando la siguiente función recursiva:\n",
    "\n",
    "```Python\n",
    "def KnapsackSolution(pos,left,ans):\n",
    "    if pos == n: return\n",
    "    if choice[pos][left]:\n",
    "        ans.append(pos)\n",
    "        left -= w[pos]\n",
    "    KnapsackSolution(pos + 1, left, ans)\n",
    "```\n",
    "\n",
    "La cual tiene una complejidad de $O(n)$, pues solamente hay una transición en cada paso y la cantidad máxima de elementos es $O(n)$.\n",
    "\n",
    "## Contest Corto de DP\n",
    "\n",
    "* [GPC-UPC DP Short Contest](https://codeforces.com/group/Hz7jTE3LqO/contest/250369)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

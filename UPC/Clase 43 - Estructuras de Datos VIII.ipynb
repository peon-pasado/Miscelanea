{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 43\n",
    "\n",
    "Para una mejor visualización entrar al siguiente [link](https://nbviewer.jupyter.org/github/racsosabe/Miscelanea/blob/master/UPC/Clase%2043%20-%20Estructuras%20de%20Datos%20VIII.ipynb)\n",
    "\n",
    "# Requisitos Previos\n",
    "\n",
    "* Heavy-Light Decomposition\n",
    "* Segment Tree\n",
    "\n",
    "# Extendiendo el HLD: Small to Large Trick\n",
    "\n",
    "Con Heavy-Light Decomposition consideramos asignar tipos a las aristas, definiendo dichos tipos para que se cumplan ciertas condiciones sobre el camino desde la raiz de un árbol hasta cada nodo $u$.\n",
    "\n",
    "Consideremos ahora el caso en el que se nos da un árbol $T$, sobre el cual nosotros queremos responder a cierta información de cada uno de sus nodos $u$, considerando que dicha información depende del subárbol de $u$.\n",
    "\n",
    "Es importante recordar la definición de arista pesada y ligera, pues debido a esta se da que existen una cantidad de $O(\\log{n})$ aristas ligeras en el camino desde la raíz del árbol hasta cualquier nodo $u$.\n",
    "\n",
    "Entonces, si pudiéramos procesar cada nodo dicha cantidad de aristas ligeras y una vez por cada cadena pesada, tendríamos una complejidad de $O(n\\log{n})$.\n",
    "\n",
    "Es ahora que podemos plantear la siguiente idea:\n",
    "\n",
    "Si procesamos con un DFS cada nodo, considerando que no borraremos la información del subárbol al cual accedemos mediante una arista pesada y aplicamos el mismo criterio en la recursión, el trabajo hecho sobre cada nodo es $O(\\log{n})$.\n",
    "\n",
    "Para que sea más sencillo de ver, propondremos el pseudocódigo:\n",
    "\n",
    "```C++\n",
    "solve(u, keep):\n",
    "    bigChild = -1\n",
    "    for v in G[u]:\n",
    "        if v is pi[u]: continue\n",
    "        if (u, v) is light-edge:\n",
    "            solve(v, false) // Resolvemos cada hijo de arista ligera pero sin guardar la información\n",
    "        else:\n",
    "            bigChild = v\n",
    "    if bigChild != -1:\n",
    "        solve(bigChild, true) // Resolvemos el hijo de arista pesada guardando la información\n",
    "    addInfo(u) // Agregamos la información de todos los hijos de arista ligera y u\n",
    "    // Resolver el nodo u con la información disponible\n",
    "    if not keep:\n",
    "        removeInfo(u) // Quitamos la información de todos los hijos de u y u\n",
    "```\n",
    "\n",
    "Si analizamos el proceso, es fácil notar que:\n",
    "\n",
    "1) Si bajamos por una arista ligera, la información es procesada 1 vez y borrada luego de ello.\n",
    "2) Si bajamos por una arista pesada, la información es procesada 1 vez y se mantiene.\n",
    "\n",
    "Debido a lo anterior, como borramos la información del nodo $u$ por cada arista ligera, tendremos que reponerla la misma cantidad de veces, en total procesaremos la información del nodo $u$ $O(\\log{n})$ veces. Finalmente, la complejidad será de $O(n\\log{n})$ inserciones y eliminaciones de información.\n",
    "\n",
    "## Implementación\n",
    "\n",
    "Se puede plantear la implementación del pseudocódigo en base al preprocesamiento del Heavy-Light Decomposition que ya tenemos, con el cual colocábamos al hijo pesado en la primera posición de la lista de adyacencia y eliminábamos al padre.\n",
    "\n",
    "```C++\n",
    "void DFS(int u, int p = -1){\n",
    "    subtree[u] = 1;\n",
    "    for(int i = 0; i < G[u].size(); i++){\n",
    "        if(G[u][i] == p){\n",
    "            swap(G[u].back(), G[u][i]);\n",
    "        }\n",
    "        int v = G[u][i];\n",
    "        if(v == p) continue;\n",
    "        DFS(v, u);\n",
    "        if(subtree[v] > subtree[G[u][0]]){\n",
    "            swap(G[u][i], G[u][0]);\n",
    "        }\n",
    "        subtree[u] += subtree[v];\n",
    "    }\n",
    "    if(p != -1){\n",
    "        G[u].pop_back();\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "void add(int u, int val, int start){\n",
    "    if(val == 1) agregarInfo(u);\n",
    "    else quitarInfo(u);\n",
    "    for(int i = start; i < G[u].size(); i++){\n",
    "        add(G[u][i], val, 0); // Solo debemos restringir en el primer nivel\n",
    "    }\n",
    "}\n",
    "\n",
    "void solve(int u, int keep){\n",
    "    for(int i = 1; i < G[u].size(); i++){\n",
    "        solve(G[u][i], 0);\n",
    "    }\n",
    "    if(!G[u].empty()) solve(G[u][0], 1);\n",
    "    add(u, 1, 1);\n",
    "    // Resolver con la información disponible\n",
    "    if(!keep){\n",
    "        add(u, -1, 0);\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Aprovechando la naturaleza de la lista de adyacencia, planteamos la función `add` con una variable $start$ que define si ignoramos o consideramos el hijo pesado, de manera que solo debemos restringir las aristas del primer nivel de descendientes (hijos directos), así que en la recursión deberemos llamar para cada hijo con $start = 0$.\n",
    "\n",
    "## Problemas para practicar\n",
    "\n",
    "- [Summing in a Tree](https://www.hackerrank.com/contests/101hack47/challenges/summing-in-a-tree)\n",
    "- [Lomsat gelral](https://codeforces.com/contest/600/problem/E)\n",
    "- [Tree Requests](https://codeforces.com/contest/570/problem/D)\n",
    "- [Tree and Queries](https://codeforces.com/problemset/problem/375/D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
